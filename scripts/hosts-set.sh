#!/bin/bash

# 检查是否以root运行
if [ "$(id -u)" -ne 0 ]; then
    echo "This script must be run as root"
    exit 1
fi

# 检查是否已执行过
if grep -q "# BEGIN_CLUSER_NODES" /etc/hosts; then
    echo "Error: This script has already been executed. Check /etc/hosts for cluster nodes."
    exit 1
fi

source /opt/cluster.conf
ZOO_SERVERS=(${ZOO_SERVER//,/ })
JOURNAL_NODES=(${JOURNAL_NODE//,/ })
DATA_NODES=(${DATA_NODE//,/ })
NODE_MANAGERS=(${NODE_MANAGER//,/ })

all_hosts=(
    ${ZOO_SERVERS[@]}
    ${JOURNAL_NODES[@]}
    $JOB_HISTORY_SERVER
    $ACTIVE_NAME_NODE $STANDBY_NAME_NODE
    $ACTIVE_RESOURCE_MANAGER $STANDBY_RESOURCE_MANAGER
    ${DATA_NODES[@]}
    ${NODE_MANAGERS[@]}
)

declare -A host_set
unique_hosts=()
for host in "${all_hosts[@]}"; do
    if [[ ! "${host_set[$host]+_}" ]]; then
        unique_hosts+=("$host")
        host_set[$host]=1
    fi
done

# 获取节点数量
total_nodes=${#unique_hosts[@]}

# 获取当前主机名和IP
current_host=$(hostname)
current_ip=$(hostname -I | awk '{print $1}')

# 验证IP格式
if ! [[ $current_ip =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
    echo "Error: Invalid IP address format: $current_ip"
    exit 1
fi

# 提取主机名中的数字部分
if [[ $current_host =~ hadoop([0-9]+) ]]; then
    current_index=${BASH_REMATCH[1]}
else
    echo "Error: Hostname must be in 'hadoopXX' format"
    exit 1
fi

# 验证节点编号有效性
if [ "$current_index" -lt 1 ] || [ "$current_index" -gt "$total_nodes" ]; then
    echo "Error: Node index $current_index is out of range (1-$total_nodes)"
    exit 1
fi

# 计算IP地址前三段
ip_base=$(echo "$current_ip" | cut -d'.' -f1-3)
last_octet=$(echo "$current_ip" | cut -d'.' -f4)

# 生成其他节点配置
config_lines=()
for (( target_index=1; target_index<=total_nodes; target_index++ )); do
    if [ "$target_index" -ne "$current_index" ]; then
        # 计算目标节点的最后一个IP段
        target_last_octet=$((last_octet + target_index - current_index))
        # 验证IP段范围
        if [ "$target_last_octet" -lt 0 ] || [ "$target_last_octet" -gt 255 ]; then
            echo "Error: Calculated invalid IP segment: $target_last_octet"
            exit 1
        fi
        target_ip="$ip_base.$target_last_octet"
        host_name="hadoop$(printf "%d" "$target_index")"
        config_lines+=("$target_ip $host_name")
    fi
done

# 写入到/etc/hosts
{
    echo ""
    echo "# BEGIN_CLUSTER_NODES (automatically generated by script, do not edit)"
    for line in "${config_lines[@]}"; do
        echo "$line"
    done
    echo "# END_CLUSER_NODES"
} >> /etc/hosts

cp /etc/hosts /tmp/hosts.tmp
sed -i "s#${ACTIVE_NAME_NODE}#${ACTIVE_NAME_NODE} hacluster#g" /tmp/hosts.tmp
sed -i "s#${STANDBY_NAME_NODE}#${STANDBY_NAME_NODE} hacluster#g" /tmp/hosts.tmp
cat /tmp/hosts.tmp | sudo tee /etc/hosts >/dev/null
rm /tmp/hosts.tmp

echo "Successfully updated /etc/hosts with cluster nodes"
